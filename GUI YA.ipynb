{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c817a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\anali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\anali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\anali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\anali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 0.23.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\anali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 0.23.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Text: ffjf fgjf jvj\n",
      "Preprocessed Text: ffjf fgjf jvj\n",
      "Preprocessed Text: love\n",
      "Preprocessed Text: love\n",
      "Preprocessed Text: love\n",
      "Preprocessed Text: love\n",
      "Preprocessed Text: love\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, StringVar, OptionMenu, Button, Label, Frame, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import re\n",
    "import pickle\n",
    "import csv\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from num2words import num2words\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from gensim.models import Word2Vec  # Import Word2Vec\n",
    "from gensim.models import KeyedVectors  # Import Word2Vec\n",
    "import joblib  # Import joblib for loading the pre-trained KNN model\n",
    "\n",
    "class SpamDetectorApp:\n",
    "    def __init__(self, master):\n",
    "        self.window = master\n",
    "        self.window.state('zoomed')\n",
    "        self.window.title('DETEKSI SPAM/HAM EMAIL')  \n",
    "\n",
    "        self.register_frame = Frame(self.window, bg=\"#ede0da\", width=1460, height=779)\n",
    "        self.bgrn_image = ImageTk.PhotoImage(Image.open('gambar/bgrnn3.png').resize((1460, 779)))\n",
    "        self.bgrnlabl = Label(self.register_frame, image=self.bgrn_image, background=\"#ede0da\")\n",
    "        self.bgrnlabl.place(x=0, y=0)\n",
    "        self.register_frame.place(x=35, y=35)\n",
    "\n",
    "        self.label = Label(self.window, text=\"Enter your text email:\", bg=\"#cbb2a6\", fg=\"#181b29\", font=(\"yu gothic ui\", 25, \"bold\"), borderwidth=0, relief=\"solid\")\n",
    "        self.label.place(x=800, y=270, anchor=\"center\")\n",
    "\n",
    "        self.entry = scrolledtext.ScrolledText(self.window, font=(\"yu gothic ui\", 20, \"bold\"), width=40, height=6, wrap='word', bd=5, relief=\"sunken\", insertbackground=\"#999999\", highlightthickness=2, highlightcolor=\"#cbb2a6\")\n",
    "        self.entry.place(x=658, y=327)  \n",
    "\n",
    "        self.detect_label = Label(self.window, text=\"Select Detection Method:\", font=(\"yu gothic ui\", 20, 'bold'), bg=\"#ede0da\", fg=\"black\", borderwidth=0)\n",
    "        self.detect_label.place(x=365, y=300, anchor=\"center\")\n",
    "\n",
    "        self.detect_methods = [\"SVM\", \"KNN\", \"Naive Bayes\"]\n",
    "        self.selected_method_var = StringVar()\n",
    "        self.selected_method_var.set(self.detect_methods[0])  \n",
    "\n",
    "        self.detect_option_menu = OptionMenu(self.window, self.selected_method_var, *self.detect_methods)\n",
    "        self.detect_option_menu.config(indicatoron=0, compound='right', font=(\"yu gothic ui \", 20,'bold'), width=12, bd=1, relief=\"solid\")\n",
    "        self.detect_option_menu[\"menu\"].config(font=(\"yu gothic ui \", 20))\n",
    "        self.detect_option_menu.place(x=365, y=435, anchor=\"center\")\n",
    "\n",
    "        self.detect_button = Button(master, text=\"Detect\", command=self.detect_selected_method, font=(\"yu gothic ui\", 20, 'bold'), bg=\"#ede0da\", fg=\"black\", borderwidth=0)\n",
    "        self.detect_button.place(x=365, y=570, anchor=\"center\")\n",
    "        self.clear_button = Button(master, text=\"Clear\", command=self.clear_entry, font=(\"yu gothic ui\", 20, 'bold'), bg='#ede0da', fg=\"black\", borderwidth=0)\n",
    "        self.clear_button.place(x=1280, y=722, anchor=\"center\")\n",
    "\n",
    "        self.load_models()\n",
    "\n",
    "    def remove_emoji(self, text):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                            u\"\\U0001F600-\\U0001F64F\"  \n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                            u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                            u\"\\U00002500-\\U00002BEF\"  \n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U000024C2-\\U0001F251\"\n",
    "                            u\"\\U0001f926-\\U0001f937\"\n",
    "                            u\"\\U00010000-\\U0010ffff\"\n",
    "                            u\"\\u2640-\\u2642\"\n",
    "                            u\"\\u2600-\\u2B55\"\n",
    "                            u\"\\u200d\"\n",
    "                            u\"\\u23cf\"\n",
    "                            u\"\\u23e9\"\n",
    "                            u\"\\u231a\"\n",
    "                            u\"\\ufe0f\"  # dingbats\n",
    "                            u\"\\u3030\"\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "\n",
    "    def nums_to_words(self, text):\n",
    "        new_text = []\n",
    "        for word in text.split():\n",
    "            if word.isdigit():\n",
    "                word_in_indonesian = num2words(int(word), lang='id', to='year')\n",
    "                new_text.append(word_in_indonesian)\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        return \" \".join(new_text)\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        no_punct = [char for char in text if char not in string.punctuation]\n",
    "        words_wo_punct = ''.join(no_punct)\n",
    "        return words_wo_punct\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = re.sub('\\S*@\\S*\\s?', '', text)  # Remove emails\n",
    "        text = re.sub('\\S*(http[s]?://|www\\.)\\S*', '', text)  # Remove URL links\n",
    "        text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)  # Remove special characters and numbers\n",
    "        text = re.sub(r\"\\b\\w{1,2}\\b\", \"\", text)  # Remove too short (2- characters) words\n",
    "        text = re.sub(r\"\\b\\w{17,}\\b\", \"\", text)  # Remove too long (17+ characters) words\n",
    "        text = re.sub(' +', ' ', text).strip()  # Remove multiple spaces\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = self.remove_punctuation(text)\n",
    "        text = self.nums_to_words(text)\n",
    "        text = self.remove_emoji(text)\n",
    "        return text\n",
    "\n",
    "    def load_models(self):\n",
    "        # Load SVM model and TF-IDF vectorizer from the tuple\n",
    "        try:\n",
    "            with open(\"svm_model.pkl\", \"rb\") as svm_file:\n",
    "                model_data = pickle.load(svm_file)\n",
    "                self.svm_model = model_data[0]  # Assuming SVM model is at index 0\n",
    "                self.tfidf_vectorizer = model_data[1]  # Assuming TF-IDF vectorizer is at index 1\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading SVM model and TF-IDF vectorizer: {str(e)}\")\n",
    "            self.svm_model = None\n",
    "            self.tfidf_vectorizer = None\n",
    "\n",
    "        # Load Word2Vec model\n",
    "        try:\n",
    "            self.knn_model = Word2Vec.load(\"w2v_model.bin\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading Word2Vec model: {str(e)}\")\n",
    "            self.knn_model = None\n",
    "\n",
    "        # Load the Naive Bayes model\n",
    "        try:\n",
    "            with open(\"Naive_model.pkl\", \"rb\") as naive_file:\n",
    "                self.naive_model = pickle.load(naive_file)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading Naive Bayes model: {str(e)}\")\n",
    "            self.naive_model = None\n",
    "\n",
    "    # Fungsi untuk Deteksi Spam menggunakan SVM:\n",
    "    def detect_svm(self):\n",
    "        self.selected_model = \"svm\"\n",
    "        preprocessed_text = self.preprocess_text(self.entry.get())\n",
    "        self.detect_spam(preprocessed_text, self.selected_model)\n",
    "\n",
    "    # Fungsi untuk Deteksi Spam menggunakan KNN:\n",
    "    def detect_knn(self):\n",
    "        self.selected_model = \"knn\"\n",
    "        preprocessed_text = self.preprocess_text(self.entry.get())\n",
    "        self.detect_spam(preprocessed_text, self.selected_model)\n",
    "\n",
    "    # Fungsi untuk Deteksi Spam menggunakan Naive Bayes:\n",
    "    def detect_naive_bayes(self):\n",
    "        self.selected_model = \"naive_bayes\"\n",
    "        preprocessed_text = self.preprocess_text(self.entry.get())\n",
    "        self.detect_spam(preprocessed_text, self.selected_model)\n",
    "\n",
    "    def detect_svm_logic(self, preprocessed_text):\n",
    "        print(\"Preprocessed Text:\", preprocessed_text)\n",
    "        if self.svm_model is None or self.tfidf_vectorizer is None:\n",
    "            messagebox.showerror(\"Error\", \"SVM model or TF-IDF vectorizer not loaded.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            text_vectorized = self.tfidf_vectorizer.transform([preprocessed_text])\n",
    "            decision_function_scores = self.svm_model.decision_function(text_vectorized)\n",
    "            threshold = 0.0\n",
    "            predictions = [1 if score > threshold else 0 for score in decision_function_scores]\n",
    "            prediction = max(set(predictions), key=predictions.count)\n",
    "\n",
    "            result_message = f\"Text Email: {preprocessed_text}\\nPrediction: {'Spam' if prediction == 1 else 'Not Spam'}\"\n",
    "            messagebox.showinfo(\"Spam Detection Result\", result_message)\n",
    "\n",
    "            self.save_to_csv(preprocessed_text, prediction)\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    def get_word2vec_vector(self, preprocessed_text):\n",
    "        words = [word for word in preprocessed_text.split() if self.knn_model.wv.has_index_for(word)]\n",
    "        if not words:\n",
    "            return None  # Jika tidak ada kata yang ada dalam vektor Word2Vec, kembalikan None\n",
    "        vectors = [self.knn_model.wv.get_vector(word) for word in words]\n",
    "        return sum(vectors) / len(vectors)\n",
    "\n",
    "    def detect_knn_logic(self, preprocessed_text):\n",
    "        print(\"Preprocessed Text:\", preprocessed_text)\n",
    "        try:\n",
    "            text_vector = self.get_word2vec_vector(preprocessed_text)\n",
    "\n",
    "            if text_vector is None:\n",
    "                messagebox.showerror(\"Error\", \"Word2Vec vector not found for preprocessed text.\")\n",
    "                return 0\n",
    "\n",
    "            similar_words = [word[0] for word in self.knn_model.wv.most_similar(positive=[text_vector], topn=5)]\n",
    "\n",
    "            # Memastikan kata yang ada dalam vektor Word2Vec sebelum melakukan evaluasi\n",
    "            similar_words = [word for word in similar_words if self.knn_model.wv.has_index_for(word)]\n",
    "\n",
    "            if any(value > 0.5 for word in similar_words for value in self.knn_model.wv[word]):\n",
    "                return 1  # Spam terdeteksi\n",
    "            else:\n",
    "                return 0  # Bukan spam\n",
    "\n",
    "        except Exception as e:\n",
    "            # Menampilkan pesan kesalahan jika terjadi kesalahan saat deteksi KNN\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred during KNN detection: {str(e)}\")\n",
    "            return 0\n",
    "\n",
    "    def detect_selected_method(self):\n",
    "        preprocessed_text = self.preprocess_text(self.entry.get(\"1.0\", \"end-1c\"))\n",
    "\n",
    "        try:\n",
    "            if self.selected_method_var.get() == \"SVM\":\n",
    "                self.detect_svm_logic(preprocessed_text)\n",
    "            elif self.selected_method_var.get() == \"KNN\":\n",
    "                prediction = self.detect_knn_logic(preprocessed_text)  # Fix the parameter passing\n",
    "                self.handle_prediction_result(preprocessed_text, prediction)\n",
    "            elif self.selected_method_var.get() == \"Naive Bayes\":\n",
    "                self.detect_naive_bayes_logic(preprocessed_text)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid model type\")\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    def handle_prediction_result(self, preprocessed_text, prediction):\n",
    "        if prediction == 1:\n",
    "            result_message = f\"Text Email: {preprocessed_text}\\nPrediction: Spam\"\n",
    "        else:\n",
    "            result_message = f\"Text Email: {preprocessed_text}\\nPrediction: Not Spam\"\n",
    "\n",
    "        messagebox.showinfo(\"Spam Detection Result\", result_message)\n",
    "        self.save_to_csv(preprocessed_text, prediction)\n",
    "\n",
    "\n",
    "    def detect_naive_bayes_logic(self, preprocessed_text):\n",
    "        print(\"Preprocessed Text:\", preprocessed_text)\n",
    "        try:\n",
    "            prediction = self.naive_model.predict([preprocessed_text])[0]\n",
    "            result_message = f\"Text Email: {preprocessed_text}\\nPrediction: {'Spam' if prediction == 1 else 'Not Spam'}\"\n",
    "            messagebox.showinfo(\"Spam Detection Result\", result_message)\n",
    "\n",
    "            self.save_to_csv(preprocessed_text, prediction)\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred during Naive Bayes detection: {str(e)}\")\n",
    "\n",
    "    def save_to_csv(self, email_text, prediction):\n",
    "        try:\n",
    "            with open(\"detection_result.csv\", mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                if file.tell() == 0:\n",
    "                    writer.writerow([\"Text Email\", \"Prediction\", \"Detection Method\"])\n",
    "                writer.writerow([email_text, \"Spam\" if prediction == 1 else \"Not Spam\", self.selected_method_var.get()])\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred while saving to CSV: {str(e)}\")\n",
    "\n",
    "    def clear_entry(self):\n",
    "        self.entry.delete(1.0, tk.END)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = SpamDetectorApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83775f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
